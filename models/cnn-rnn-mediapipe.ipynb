{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign language recognition using hand pose estimation of MediaPipe and CNN-RNN\n",
    "Architettura ibrida CNN-RNN utilizzata per riconoscere il linguaggio dei segni, combinata con l'approccio hand pose estimation della libreria MediaPipe di Google. Il dataset utilizzato nello specifico è quello relativo all'alfabeto della lingua dei segni americana (ASL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caricamento del dataset\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "train_dir = \"./SigNN Character Database\"\n",
    "unique_labels = sorted(os.listdir(train_dir)) # labels ordinate\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione dei punti chiave della mano con MediaPipe\n",
    "Vengono caricate tutte le immagini del dataset e vengono estratti i punti chiave della mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for idx, label in enumerate(unique_labels):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    print(\"Loading \" + label)\n",
    "    for file in os.listdir(train_dir + \"/\" + label):\n",
    "        filepath = train_dir + \"/\" + label + \"/\" + file\n",
    "        image = cv2.imread(filepath)               # images NOT flipped\n",
    "        #image = cv2.flip(cv2.imread(filepath), 1) # images flipped\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print handedness and draw hand landmarks on the image.\n",
    "        #print('Handedness:', results.multi_handedness)\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        image_hight, image_width, _ = image.shape\n",
    "        #annotated_image = image.copy()\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks_xyz = []\n",
    "            for i in range(21):\n",
    "                landmark = hand_landmarks.landmark[i]\n",
    "                landmarks_xyz.append(landmark.x)\n",
    "                landmarks_xyz.append(landmark.y)\n",
    "                landmarks_xyz.append(landmark.z)  \n",
    "            images.append(np.array(landmarks_xyz))\n",
    "            labels.append(idx)\n",
    "            \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "hands.close()\n",
    "\n",
    "# Save data\n",
    "np.save(\"images.npy\", images)\n",
    "np.save(\"labels.npy\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per caricare i dati estratti da MediaPipe senza dover ripetere il processo di classificazione\n",
    "images = np.load(\"./images.npy\")\n",
    "labels = np.load(\"./labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape,images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serie di import \n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,Reshape,Permute\n",
    "from keras.layers import Conv2D, MaxPooling2D,SimpleRNN,LSTM\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione di train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione del modello\n",
    "Una CNN combinata con una RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 63, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 63, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 26\n",
    "epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu', input_shape=(63,1,1)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# Reshape with the first argument being the number of filter in your last conv layer\n",
    "model.add(Reshape((64, -1)))\n",
    "model.add(Permute((2, 1)))\n",
    "# può essere anche una LSTM\n",
    "model.add(SimpleRNN(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addestramento del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valutazione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_b_model = model.predict(X_test)\n",
    "result = model.evaluate(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, r2_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Confusion matrix\n",
    "#Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y, y_pred, title, normalize=False):\n",
    "    if y.ndim>1:\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(unique_labels))\n",
    "    plt.xticks(tick_marks, unique_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, unique_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    ax.set(title = title)\n",
    "    limit = cm.max() / 2.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if cm[i,j] < 0.01:\n",
    "            plt.text(j, i, format(0, 'd'), horizontalalignment = \"center\",color = \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")        \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "\n",
    "#plot_confusion_matrix(y_test, y_pred_svm_model, title='Confusion matrix For SVM Model (24)', normalize=True)\n",
    "plot_confusion_matrix(y_test, y_pred_b_model, title='Confusion matrix for b_model', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
